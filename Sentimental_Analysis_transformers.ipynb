{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPriNQKB7XX9rXgop9ILkU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1fc6cf566d7d42279adebbaa4a853fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37e49884806140138d8fb9551165d2ce",
              "IPY_MODEL_ee9401708c3a4a5995af0a3b676afdef",
              "IPY_MODEL_a51b45dcdfb0441d869ad1f520bac633"
            ],
            "layout": "IPY_MODEL_3a71782e5c71499282c8fe124d58256b"
          }
        },
        "37e49884806140138d8fb9551165d2ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_074d83c0e60d4549b1bb4a3c10eb2f19",
            "placeholder": "​",
            "style": "IPY_MODEL_fb762396d9ba497fbead8d9b677ed3ea",
            "value": "model.safetensors: 100%"
          }
        },
        "ee9401708c3a4a5995af0a3b676afdef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8a327d76290481c93327d71626d1506",
            "max": 435755784,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_144d428869034d52ab8d339fb67b70b1",
            "value": 435755784
          }
        },
        "a51b45dcdfb0441d869ad1f520bac633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85868eac8a4340169b6a98b3134a8f1b",
            "placeholder": "​",
            "style": "IPY_MODEL_c03c0aafc6f64d8ca677268c9d99cee5",
            "value": " 436M/436M [00:17&lt;00:00, 32.6MB/s]"
          }
        },
        "3a71782e5c71499282c8fe124d58256b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "074d83c0e60d4549b1bb4a3c10eb2f19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb762396d9ba497fbead8d9b677ed3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8a327d76290481c93327d71626d1506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "144d428869034d52ab8d339fb67b70b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85868eac8a4340169b6a98b3134a8f1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c03c0aafc6f64d8ca677268c9d99cee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nashra-Tazmeen/sentimental-model-with-TF-and-transformers/blob/main/Sentimental_Analysis_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Nashra-Tazmeen/sentimental-model-with-TF-and-transformers.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2nd5vXfBR8A",
        "outputId": "cdd54da9-e296-4175-c99e-587a743efb94"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'sentimental-model-with-TF-and-transformers' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n36lWy2LC53u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Preparing Data:**\n",
        "\n",
        "We will start by reading the data into a Pandas Dataframe using th read_csv function. Because we're working with .tsv (tab seperate values) files we need to specify that we will be taking tab characters as the delimiters:"
      ],
      "metadata": {
        "id": "UUVBc4xMC6QA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the TSV file\n",
        "df = pd.read_csv(\"/content/sentimental-model-with-TF-and-transformers/train.tsv\", delimiter='\\t')\n",
        "\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "pdTuj4p8B5Zy",
        "outputId": "d2e0dc92-3157-433b-ffdc-1792fc77845a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        PhraseId  SentenceId  \\\n",
              "0              1           1   \n",
              "1              2           1   \n",
              "2              3           1   \n",
              "3              4           1   \n",
              "4              5           1   \n",
              "...          ...         ...   \n",
              "156055    156056        8544   \n",
              "156056    156057        8544   \n",
              "156057    156058        8544   \n",
              "156058    156059        8544   \n",
              "156059    156060        8544   \n",
              "\n",
              "                                                   Phrase  Sentiment  \n",
              "0       A series of escapades demonstrating the adage ...          1  \n",
              "1       A series of escapades demonstrating the adage ...          2  \n",
              "2                                                A series          2  \n",
              "3                                                       A          2  \n",
              "4                                                  series          2  \n",
              "...                                                   ...        ...  \n",
              "156055                                          Hearst 's          2  \n",
              "156056                          forced avuncular chortles          1  \n",
              "156057                                 avuncular chortles          3  \n",
              "156058                                          avuncular          2  \n",
              "156059                                           chortles          2  \n",
              "\n",
              "[156060 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed28d10d-da12-4db1-9301-13f29d550620\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156055</th>\n",
              "      <td>156056</td>\n",
              "      <td>8544</td>\n",
              "      <td>Hearst 's</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156056</th>\n",
              "      <td>156057</td>\n",
              "      <td>8544</td>\n",
              "      <td>forced avuncular chortles</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156057</th>\n",
              "      <td>156058</td>\n",
              "      <td>8544</td>\n",
              "      <td>avuncular chortles</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156058</th>\n",
              "      <td>156059</td>\n",
              "      <td>8544</td>\n",
              "      <td>avuncular</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156059</th>\n",
              "      <td>156060</td>\n",
              "      <td>8544</td>\n",
              "      <td>chortles</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>156060 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed28d10d-da12-4db1-9301-13f29d550620')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ed28d10d-da12-4db1-9301-13f29d550620 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ed28d10d-da12-4db1-9301-13f29d550620');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-09cb8f41-b73e-43d3-8a02-b64fa4f39216\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-09cb8f41-b73e-43d3-8a02-b64fa4f39216')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-09cb8f41-b73e-43d3-8a02-b64fa4f39216 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e74a9fcf-59c2-4449-8627-d21ea91b7a0b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e74a9fcf-59c2-4449-8627-d21ea91b7a0b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Phrase column contains all of our text data that we will be processing. We can also see that there are many copies through segments of the same answer (note that the SentenceId value for each of these copies is identical). We can reduce the amount of noise in our dataset by removing these duplicates."
      ],
      "metadata": {
        "id": "upki_qzUC9R-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the distribution of sentiment classes across our data."
      ],
      "metadata": {
        "id": "Zh0sAAQUDqSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentiment'].value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "DefnBt2ZDgGn",
        "outputId": "67aafb38-be13-49d1-ad2a-3da42c881034"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Sentiment'>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be tokenizing this text to create two input tensors; our input IDs, and attention mask.\n",
        "\n",
        "We will contain our tensors within two numpy arrays, which will be of dimensions len(df) * 512 - the 512 is the sequence length of our tokenized sequences for BERT, and len(df) the number of samples in our dataset."
      ],
      "metadata": {
        "id": "2GKbQgngJmyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "seq_len = 512\n",
        "num_samples = len(df)\n",
        "\n",
        "num_samples, seq_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFNcccf_Jn-O",
        "outputId": "988d2b42-7d45-4b80-ba3c-ef5f237fe0b4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156060, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can begin tokenizing with a BertTokenizer, like so:"
      ],
      "metadata": {
        "id": "MINoJZUOJugx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# initialize tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "# tokenize - this time returning Numpy tensors\n",
        "tokens = tokenizer(df['Phrase'].tolist(), max_length=seq_len, truncation=True,\n",
        "                   padding='max_length', add_special_tokens=True,\n",
        "                   return_tensors='np')"
      ],
      "metadata": {
        "id": "UtLULwkgJvGm"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which returns us three numpy arrays - input_ids, token_type_ids, and attention_mask."
      ],
      "metadata": {
        "id": "sO91FU7RKBOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1CRsxKoKCDU",
        "outputId": "e6d2aae8-f933-4358-d86c-9bd8efd92b2d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens['input_ids'][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyowB6v1KPV2",
        "outputId": "04c44104-d72e-41ea-924d-eabd8747e8fd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  101,   138,  1326, ...,     0,     0,     0],\n",
              "       [  101,   138,  1326, ...,     0,     0,     0],\n",
              "       [  101,   138,  1326, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101, 13936, 25265, ...,     0,     0,     0],\n",
              "       [  101, 13936, 25265, ...,     0,     0,     0],\n",
              "       [  101, 15107,  1103, ...,     0,     0,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens['attention_mask'][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5cyZhr0KS8e",
        "outputId": "183fc886-e391-4050-c6ef-d375edbb620d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('movie-xids.npy', 'wb') as f:\n",
        "    np.save(f, tokens['input_ids'])\n",
        "with open('movie-xmask.npy', 'wb') as f:\n",
        "    np.save(f, tokens['attention_mask'])"
      ],
      "metadata": {
        "id": "j-wYhljBKYHb"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del tokens"
      ],
      "metadata": {
        "id": "2LUyLtRYKrYy"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our input tensors are prepared, but we haven't touched our target data yet. So, let's move onto that.\n",
        "\n",
        "Presently our target data is a set of integer values (representing sentiment classes) in the Sentiment column of our dataframe df. We need to extract these values and one-hot encode them into another numpy array, which will have the dimensions len(df) * number of label classes. Again, we will initialize a numpy zero array beforehand, but we won't populate it row by row - we will use some fancy indexing techniques instead."
      ],
      "metadata": {
        "id": "MHdeaEm1LY6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first extract sentiment column\n",
        "arr = df['Sentiment'].values"
      ],
      "metadata": {
        "id": "HWn95D3TLZyw"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we then initialize the zero array\n",
        "labels = np.zeros((num_samples, arr.max()+1))\n",
        "labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_5Mfm--LeFH",
        "outputId": "911dbdb3-44e2-4330-d4e4-2a49760e7b35"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156060, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are able to use arr.max()+1 to define our second dimension here because we have the values [0, 1, 2, 3, 4] in our Sentiment column, there are five unique labels which means we need our labels array to have five columns (one for each) - arr.max() = 4, so we do 4 + 1 to get our required value of 5.\n",
        "\n",
        "Now we use the current values in our arr of [0, 1, 2, 3, 4] to place 1 values in the correct positions of our presently zeros-only array:"
      ],
      "metadata": {
        "id": "40-T_P3sLiKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels[np.arange(num_samples), arr] = 1\n",
        "\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoZx7DD5LkRO",
        "outputId": "65fd8f56-687c-4999-c165-f6b3744740d4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('movie-labels.npy', 'wb') as f:\n",
        "    np.save(f, labels)"
      ],
      "metadata": {
        "id": "WMQQAl-BLq3F"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input pipeline**"
      ],
      "metadata": {
        "id": "qE6YwtvM6XL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "RQ2iVOzrcKv8"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "As we're using TensorFlow we can make use of the tf.data.Dataset object. First, we'll load in our Numpy binaries from file:"
      ],
      "metadata": {
        "id": "cROrUo4P6gV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('movie-xids.npy','rb') as f:\n",
        "  xids=np.load(f,allow_pickle=True)\n",
        "with open('movie-xmask.npy','rb') as f:\n",
        "  xmask=np.load(f,allow_pickle=True)\n",
        "with open('movie-labels.npy','rb') as f:\n",
        "  labels=np.load(f,allow_pickle=True)"
      ],
      "metadata": {
        "id": "zsMa-XTPcM4n"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xids.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T63oyqVSdO7Q",
        "outputId": "3f454fc6-0941-49f9-ea0f-f59dc47f64d7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156060, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72ta7m78dV7m",
        "outputId": "2316aaf2-b495-4969-de46-f084685a4296"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "0I4lhAA2dXwI"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can take these three arrays and create a TF dataset object with them using from_tensor_slices like so:"
      ],
      "metadata": {
        "id": "m6PsjyZh6rB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=tf.data.Dataset.from_tensor_slices((xids,xmask,labels))"
      ],
      "metadata": {
        "id": "gjVM4ojwdbii"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YJHKUBbduH-",
        "outputId": "83b6b430-fc79-4b05-da29-20b0f55ce480"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TakeDataset element_spec=(TensorSpec(shape=(512,), dtype=tf.int64, name=None), TensorSpec(shape=(512,), dtype=tf.int64, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each sample in our dataset is a tuple containing a single Xids, Xmask, and labels tensor. However, when feeding data into our model we need a two-item tuple in the format (<inputs>, <outputs>). Now, we have two tensors for our inputs - so, what we do is enter our <inputs> tensor as a dictionary:\n",
        "\n",
        "\n",
        "{\n",
        "    'input_ids': <input_id_tensor>,\n",
        "    'attention_mask': <mask_tensor>\n",
        "}"
      ],
      "metadata": {
        "id": "4e0a6l4z6xLi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To rearrange the dataset format we can map a function that modifies the format like so:"
      ],
      "metadata": {
        "id": "dCPYDLiT7dlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_func(input_ids,masks,labels):\n",
        "  # we convert our three-item tuple into a two-item tuple where the input item is a dictionary\n",
        "  return{'input_ids':input_ids,\n",
        "         'attention_mask':masks},labels"
      ],
      "metadata": {
        "id": "LHB1Rib6eQoh"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# then we use the dataset map method to apply this transformation\n",
        "dataset=dataset.map(map_func)"
      ],
      "metadata": {
        "id": "xaHT1T9jepGR"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMfdWB0Mevy-",
        "outputId": "91b0225f-2b30-4577-b8e5-111c277328c1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TakeDataset element_spec=({'input_ids': TensorSpec(shape=(512,), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(512,), dtype=tf.int64, name=None)}, TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can see that our dataset sample format has been changed. Next, we need to shuffle our data, and batch it. We will take batch sizes of 16 and drop any samples that don't fit evenly into chunks of 16."
      ],
      "metadata": {
        "id": "_sojTom-7zB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=16\n"
      ],
      "metadata": {
        "id": "tD6X3qINe1TM"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=dataset.shuffle(10000).batch(batch_size,drop_remainder=True)"
      ],
      "metadata": {
        "id": "SZwD_iYVfE-I"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn7md_kNfYY4",
        "outputId": "19f8c600-f4fb-4985-e6d2-90e18e01e987"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now our dataset samples are organized into batches of 16. The final step is to split our data into training and validation sets. For this we use the take and skip methods, creating and 90-10 split."
      ],
      "metadata": {
        "id": "5HifmrsD-f_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split=0.9"
      ],
      "metadata": {
        "id": "TFSai6iPferc"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size=xids.shape[0]\n",
        "size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPRJVeaefglQ",
        "outputId": "d0f4d031-e887-4d38-d7f1-e9d026bd9170"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156060"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int((xids.shape[0]/batch_size)*split)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYFeXUpMfmoi",
        "outputId": "edbbc619-ea67-4f4d-8f7d-964856a3b5b5"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8778"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds=dataset.take(size)\n",
        "val_ds=dataset.skip(size)"
      ],
      "metadata": {
        "id": "dcnW5ElcgyDg"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our two datasets are fully prepared for our model inputs. Now, we can save both to file using tf.data.experimental.save."
      ],
      "metadata": {
        "id": "pZ9PZVpa_G_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.data.experimental.save(train_ds,'train')\n",
        "tf.data.experimental.save(val_ds,'val')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECtHEMRjhCNw",
        "outputId": "c88abfe7-ae07-47d8-a266-254fc6ebe2b7"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-69-8d7608fa7fdf>:1: save (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.save(...)` instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.element_spec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJYTBqwjiAwH",
        "outputId": "2f13ee36-62a4-418e-f222-550b938e6301"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None),\n",
              "  'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int64, name=None)},\n",
              " TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.element_spec==val_ds.element_spec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_h4N14wh1bC",
        "outputId": "50a629dc-073d-4f25-be1c-b05884242aa9"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build and Train**\n",
        "Now we're ready to begin building our sentiment classifier and begin training. We will be building out what is essentially a frame around Bert, that will allow us to perform language classification. First, we can initialize the Bert model, which we will load as a pretrained model from transformers."
      ],
      "metadata": {
        "id": "Et9QmgvF_cLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "bert = TFAutoModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "# we can view the model using the summary method\n",
        "bert.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347,
          "referenced_widgets": [
            "1fc6cf566d7d42279adebbaa4a853fbc",
            "37e49884806140138d8fb9551165d2ce",
            "ee9401708c3a4a5995af0a3b676afdef",
            "a51b45dcdfb0441d869ad1f520bac633",
            "3a71782e5c71499282c8fe124d58256b",
            "074d83c0e60d4549b1bb4a3c10eb2f19",
            "fb762396d9ba497fbead8d9b677ed3ea",
            "f8a327d76290481c93327d71626d1506",
            "144d428869034d52ab8d339fb67b70b1",
            "85868eac8a4340169b6a98b3134a8f1b",
            "c03c0aafc6f64d8ca677268c9d99cee5"
          ]
        },
        "id": "UNijmqNWh9Xe",
        "outputId": "e8d75b75-ab38-4e14-b7be-2b9cd3ad5476"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fc6cf566d7d42279adebbaa4a853fbc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_bert_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bert (TFBertMainLayer)      multiple                  108310272 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 108310272 (413.17 MB)\n",
            "Trainable params: 108310272 (413.17 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we need to define the frame around Bert, we need:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Two input layers (one for input IDs and one for attention mask).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "A post-bert dropout layer to reduce the likelihood of overfitting and improve generalization.\n",
        "\n",
        "Max pooling layer to convert the 3D tensors output by Bert to 2D.\n",
        "\n",
        "Final output activations using softmax for outputting categorical probabilities."
      ],
      "metadata": {
        "id": "NEdyhPyYBEEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ugzxamHPBXJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Example input\n",
        "input_text = \"Example input text to obtain BERT embeddings.\"\n",
        "\n",
        "# Tokenize input text\n",
        "input_ids = tokenizer.encode(input_text, add_special_tokens=True, return_tensors='tf')\n",
        "\n",
        "# Get BERT embeddings\n",
        "outputs = bert_model(input_ids)\n",
        "embeddings = outputs[1]  # Access final activations (already max-pooled)\n",
        "\n",
        "# Continue with your downstream tasks using BERT embeddings\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MihJzzYTPiv9",
        "outputId": "769846dd-f6b3-486f-f2b0-54fd378df5d5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now define our model, specifying input and output layers. Finally, we can freeze the Bert layer because Bert is already highly trained, and contains a huge number of parameters so will take a very long time to train further. Nonetheless, if you'd like to train Bert too, there is nothing wrong with doing so."
      ],
      "metadata": {
        "id": "aawdiXe2QA2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Initialize the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Example texts\n",
        "texts = [\"This is a test sentence.\", \"Another example sentence.\"]\n",
        "\n",
        "# Tokenize the texts\n",
        "tokenized_inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='tf')\n",
        "\n",
        "# Extract input tensors\n",
        "input_ids = tokenized_inputs['input_ids']\n",
        "attention_mask = tokenized_inputs['attention_mask']\n",
        "\n",
        "# Define the model\n",
        "input_ids_input = tf.keras.Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
        "attention_mask_input = tf.keras.Input(shape=(None,), dtype=tf.int32, name='attention_mask')\n",
        "bert_outputs = bert_model(input_ids=input_ids_input, attention_mask=attention_mask_input)\n",
        "# Add further layers and define the rest of the model architecture\n"
      ],
      "metadata": {
        "id": "9auQmTlWP5M3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the optimizer using the legacy optimizer\n",
        "optimizer_legacy = tf.keras.optimizers.legacy.Adam(learning_rate=0.001, decay=1e-6)  # Example learning rate and decay\n",
        "\n",
        "# Compile the model with the legacy optimizer\n",
        "model.compile(optimizer=optimizer_legacy, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "YImkj2UfQnQR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "element_spec = ({'input_ids': tf.TensorSpec(shape=(16, 512), dtype=tf.float64, name=None),\n",
        "                 'attention_mask': tf.TensorSpec(shape=(16, 512), dtype=tf.float64, name=None)},\n",
        "                tf.TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))\n",
        "\n",
        "# load the training and validation sets\n",
        "train_ds = tf.data.experimental.load('train', element_spec=element_spec)\n",
        "val_ds = tf.data.experimental.load('val', element_spec=element_spec)\n",
        "\n",
        "# view the input format\n",
        "train_ds.take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mU1ea2WcQyJE",
        "outputId": "4f3d9dd9-ddaf-4a6e-de03-116a080bfad9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.float64, name=None), 'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.float64, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=3\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qVBFbKszQ3J2",
        "outputId": "5814628a-362f-45a7-9cec-2860c1da8a78"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node IteratorGetNext defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-15-dd164fcc4556>\", line 1, in <cell line: 1>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1804, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1398, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1380, in step_function\n\nData type mismatch at component 0: expected double but got int64.\n\t [[{{node IteratorGetNext}}]] [Op:__inference_train_function_82956]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-dd164fcc4556>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node IteratorGetNext defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-15-dd164fcc4556>\", line 1, in <cell line: 1>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1804, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1398, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/tf_keras/src/engine/training.py\", line 1380, in step_function\n\nData type mismatch at component 0: expected double but got int64.\n\t [[{{node IteratorGetNext}}]] [Op:__inference_train_function_82956]"
          ]
        }
      ]
    }
  ]
}